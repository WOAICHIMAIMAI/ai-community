# 新闻热点模块实现方案

## 核心技术选型
- 采用**Jsoup**作为网络爬虫工具
- 数据库使用**MySQL**存储新闻数据
- 配合**Redis**缓存热点新闻

## 新闻源分类策略

### 综合性新闻源
1. **国内权威媒体**
   - 人民网（政治要闻）
   - 新华网（时政报道）
2. **商业门户网站**
   - 新浪新闻（综合热点）
   - 网易新闻（社会新闻）
3. **国际媒体**
   - BBC（国际视角）
   - CNN（全球报道）

### 垂直领域新闻源
| 分类 | 代表网站 | 特点 |
|------|----------|------|
| 财经 | 华尔街见闻、财新网 | 实时行情分析 |
| 科技 | 36氪、TechCrunch | 创业公司动态 |
| 体育 | 腾讯体育、虎扑 | 赛事即时报道 |
| 娱乐 | 豆瓣电影、微博 | 影视综艺资讯 |

## 智能爬取调度系统

### 频率控制
- **高频更新类**（财经/科技）
   - 执行间隔：每小时1次
   - 错峰设置：xx:03分执行
- **常规更新类**（国内/国际）
   - 执行间隔：3小时1次
   - 错峰设置：xx:15分执行
- **低频更新类**（体育/娱乐）
   - 每日采集：9:30/14:00/20:00

### 防重复机制
1. **URL查重**
   - 布隆过滤器预判（10万容量）
   - 数据库唯一索引二次校验
2. **内容去重**
   - SimHash算法（64位指纹）
   - 汉明距离阈值：≤3视为重复

### 虚拟线程异步更新数据库数据
1. **使用Semaphore控制虚拟线程数**
    - 定义Semaphore为10
    - 通过acquire和release方法控制虚拟线程数
2. **分块提交任务**
    - 定义chunk为50
    - 批量提交chunk至虚拟线程
   
### 数据库索引优化
1. **索引优化**
    - 高频查询列如source_url、content_hash添加索引

## 性能优化对比

### 数据库优化
| 优化点         | 实施前              | 实施后              |
|---------------|---------------------|---------------------|
| 查询方式       | 全表扫描            | 索引查询            |
| 事务处理       | 批量提交            | 单条提交+异常隔离   |
| 字段设计       | TEXT不限长          | VARCHAR(2000)       |

### 性能指标提升
- 平均处理耗时：20s → **5s**（↓75%）
- 数据库负载：峰值QPS 300 → **稳定60**
- 内存消耗：+2MB（布隆过滤器）

## 关键技术实现

### 布隆过滤器判重流程（Guava）
1. **数据加载**
   - 数据库查询url
   - 启动时加载布隆过滤器
2. **判重**
   - 对抓取到的url进行判重


### 相似内容检测流程
1. **文本预处理**
   - 中文分词（正则初步切分）
2. **特征提取**
   - 词频统计（Top50关键词）
   - MD5生成64位二进制指纹
   - 转换为16位字符串
3. **相似判定**
   - 异或计算汉明距离
   - 动态阈值控制（3-5位）


##### 整个流程：在我设计新闻板块的时候，除了必须的CRUD操作，我考虑到了数据从哪里获取，我选择了一个爬虫策略。此时就想到了一些问题，比如数据在哪里爬，什么时候爬虫，多久爬。对于这些问题，我的思路是先对文章的类型进行分类（财经、科技、体育、娱乐），然后不同的分类又可以按照频率进行划分，高频率新闻（财经、娱乐、体育）。低频率新闻（科技），划分的依据是事件发生频率、媒体报道频率、用户关注度。对于高频率新闻可以每个小时爬取一次，对于低频率新闻可以每六个小时爬取一次。除此之外我采取了一种错峰爬取的方式，每种类型不会再整点进行爬取（10:03），并且每种新闻对应一个网站的爬取，不同的爬取也都是错峰的，这样就避免了短时间内大量的数据处理压力。后来经过测试发现会爬取到重复的数据，有两种优化方案：1.优化爬取时的样式选择器 2.爬取到的数据进行去重。从复杂度考虑，我选择了第二种方案，因为第一种方案对爬取的能力较高，远远高于第二种。而使用第二种就需要考虑到什么方式能高效地实现去重，我第一时间就想到了用于解决缓存穿透问题地布隆过滤器，实现布隆过滤器的方式常见的有三种，guava、common、redisson，其中common提供的布隆过滤器性能较差，就不考虑了，主要考虑guava和redisson。guava是一种基于本地内存的布隆过滤器，实现简单，只需调用简单API，缺点是数据不是持久化。redisson是一种基于Redis的布隆过滤器，实现相较而言复杂一些，但是数据能够持久化。最后综合性能和实现复杂度我选择了guava，首先设置数组容量以及误判率，因为guava的布隆过滤器不具有持久化数据的功能，因此每次项目启动需要通过PostConstructor加载一数据，每次爬取到新闻列表进行逐条判断url是否重复即可。此时我又考虑到新闻过多堆积在数据库中，数据量过大，如果加载到布隆过滤器中会超过我设置的10000容量，从而导致误判率大幅度升高，因此我采用了一种定时任务清理五天前新闻的措施。之后为了扩充数据源，我就多加了几个爬虫去不同的网站爬取相同的数据，此时又引出了新的问题，不同的网站可能存在url不同的新闻，但是内容相似，这是布隆过滤器无法判断的。为了解决这个问题我借鉴了谷歌提供的SimHash算法，SimHash算法是一种用于快速判重的算法，他可以将任意长度的字符串转换为相同位的特征值，然后通过计算汉明距离来判断重复度是否高。主要流程是这样的：1。分词计算权重 2.遍历每个词语，转换为二进制，补0或截取为64位二进制 3.遍历每一位，根据位值来计算特征值 4.特征值转换为16位字符串 5.从Redis缓存中拿到所有特征值，每一位进行异或操作，计算汉明距离，小于阈值说明相似。于是爬虫中的判重机制就是先通过布隆过滤器筛选，先过滤掉相同url的新闻，然后再通过SimHash算法进行二次判断。最后为了优化数据库的插入操作，我将爬虫拿到的数据每50条进行划分，并且利用JDK21推出的虚拟线程进行数据库数据的插入，这样做的好处是避免了大规模数据的回滚，并利用相对较为廉价的虚拟线程来处理I/O操作。最终通过测试单词爬虫从一开始的响应时间20s+到最后的5秒左右。

   
# 点赞功能优化方案

#### 点赞功能的性能瓶颈主要在写性能上，每次写操作都需要通过数据库进行判断用户是否已点赞，这是非常慢的，因此我就考虑引入Redis，通过Redis中的Hash结构，大key为userId,小Key为type:targetId，value为1即代表当前用户已经点赞。由于每次判断完还需要新增或删除Redis的记录，为了保证原子性，我选择使用Lua脚本，Lua脚本可以让我Redis使用事务来执行脚本，从而保证原子性（这里的原子性指的是多线程的原子性，一个操作不可分割）。除此之外，我还考虑使用消息