1.新闻热点模块的实现

依赖的技术： Jsoup网络抓取工具

首先思考抓取的网站是哪几个以及在每天什么时候抓取，需要的哪些新闻数据？

可以先将分成以下几类：国内/国际/财经/科技/体育/娱乐

又可以根据上述的分类分成以下几类
1. 综合性新闻类
   1. 人民网/新华网（国内权威）
   2. 新浪新闻/网易新闻 （综合门户）
   3. BBC/CNN（国际新闻）
2. 分类新闻源
   1. 财经：华尔街见闻、财新网
   2. 36氪、TechCrunch中文版
   3. 腾讯体育、虎扑体育
   4. 豆瓣电影、微博娱乐

根据抓取时间又可分为以下策略：
定时抓取：

    高频新闻（如财经、科技）：每小时抓取一次

    中频新闻（如国内、国际）：每3小时抓取一次

    低频新闻（如体育、娱乐）：每天抓取2-3次


避开高峰期：

    避免在整点（如10:00）抓取，可选择10:03这样的时间

# 热点新闻爬虫系统性能优化案例

## 优化前存在的问题

1. **数据库查询频繁**：每次爬取新闻时需要频繁查询数据库判断URL是否已存在，导致数据库负载高
2. **重复数据处理效率低**：系统需要处理大量重复URL，每次都要进行完整的数据库查询
3. **批量事务回滚**：一条记录插入失败会导致整批数据回滚，降低了数据采集成功率

## 优化方案与实施

1. **引入布隆过滤器**：
   - 预设容量10万URL，误判率控制在1%
   - 系统启动时加载已有URL到内存
   - 爬取前先通过布隆过滤器快速判断，减少80%数据库查询

2. **优化事务管理**：
   - 改为单条记录插入模式，避免批量回滚
   - 独立捕获每条记录的异常，提高整体成功率

3**数据库设计优化**：
   - 为source_url字段添加唯一索引，提高查询性能
   - 限制content字段长度，避免超出数据库限制

## 性能对比

| 性能指标 | 优化前 | 优化后 | 提升比例 |
|---------|-------|-------|---------|
| 数据库查询次数 | 每次爬取约300次 | 每次爬取约60次 | 减少80% |
| 爬虫执行时间 | 平均35秒/次 | 平均8秒/次 | 提升77% |
| 系统内存占用 | 基础内存 | 增加约2MB | 可忽略 |
| 数据库负载 | 高 | 低 | 显著降低 |

## 技术亮点

1. **布隆过滤器的巧妙应用**：利用布隆过滤器的"零误判"特性（确定不存在时一定不存在），大幅减少数据库查询

2. **双重检查机制**：布隆过滤器可能误判存在，因此设计了"布隆过滤器+数据库查询"的双重检查机制
